{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA) for Tamil and Malayalam Text Classification\n",
    "\n",
    "This notebook provides an exploratory data analysis (EDA) for a dataset containing Tamil and Malayalam texts, classified into \"Abusive\" and \"Non-Abusive\" categories. The analysis includes text statistics, script detection, class distribution, and visualizations to better understand the dataset.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Analysis Function\n",
    "\n",
    "We will start by defining a function to analyze the dataset, which includes basic statistics, text length, word count, and language script distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataset(data, set_name=\"Dataset\"):\n",
    "    \"\"\"Analyze text dataset and print insights, including data quality checks\"\"\"\n",
    "    print(f\"\\n{set_name} Analysis:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(\"\\n1. Basic Statistics:\")\n",
    "    print(f\"Total samples: {len(data)}\")\n",
    "    \n",
    "    # Null values check\n",
    "    print(\"\\nNull Values Check:\")\n",
    "    print(data.isnull().sum())\n",
    "    \n",
    "    # Unique values check for each column\n",
    "    print(\"\\nUnique Values per Column:\")\n",
    "    for col in data.columns:\n",
    "        unique_vals = data[col].nunique()\n",
    "        print(f\"{col}: {unique_vals} unique values\")\n",
    "    \n",
    "    # Class distribution\n",
    "    class_dist = data['Class'].value_counts()\n",
    "    print(\"\\nClass Distribution:\")\n",
    "    for cls, count in class_dist.items():\n",
    "        percentage = (count/len(data))*100\n",
    "        print(f\"{cls}: {count} ({percentage:.2f}%)\")\n",
    "    \n",
    "    # Text length statistics\n",
    "    data['text_length'] = data['Text'].astype(str).apply(len)\n",
    "    data['word_count'] = data['Text'].astype(str).apply(lambda x: len(x.split()))\n",
    "    \n",
    "    print(\"\\n2. Text Length Statistics:\")\n",
    "    print(\"\\nCharacter Count:\")\n",
    "    print(f\"Mean: {data['text_length'].mean():.2f}\")\n",
    "    print(f\"Median: {data['text_length'].median():.2f}\")\n",
    "    print(f\"Min: {data['text_length'].min()}\")\n",
    "    print(f\"Max: {data['text_length'].max()}\")\n",
    "    \n",
    "    print(\"\\nWord Count:\")\n",
    "    print(f\"Mean: {data['word_count'].mean():.2f}\")\n",
    "    print(f\"Median: {data['word_count'].median():.2f}\")\n",
    "    print(f\"Min: {data['word_count'].min()}\")\n",
    "    print(f\"Max: {data['word_count'].max()}\")\n",
    "    \n",
    "    # Language script analysis\n",
    "    def detect_script(text):\n",
    "        tamil = len(re.findall(r'[\\u0B80-\\u0BFF]', str(text)))\n",
    "        malayalam = len(re.findall(r'[\\u0D00-\\u0D7F]', str(text)))\n",
    "        if tamil > malayalam:\n",
    "            return 'Tamil'\n",
    "        elif malayalam > tamil:\n",
    "            return 'Malayalam'\n",
    "        else:\n",
    "            return 'Other/Mixed'\n",
    "    \n",
    "    data['script'] = data['Text'].apply(detect_script)\n",
    "    \n",
    "    print(\"\\n3. Script Distribution:\")\n",
    "    script_dist = data['script'].value_counts()\n",
    "    for script, count in script_dist.items():\n",
    "        percentage = (count/len(data))*100\n",
    "        print(f\"{script}: {count} ({percentage:.2f}%)\")\n",
    "    \n",
    "    # Cross tabulation of script and class\n",
    "    print(\"\\n4. Script vs Class Distribution:\")\n",
    "    cross_tab = pd.crosstab(data['script'], data['Class'])\n",
    "    print(cross_tab)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualization Function\n",
    "\n",
    "We will define a function that generates various visualizations to explore class distribution, text length, word count, and script distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distributions(data, set_name=\"Dataset\"):\n",
    "    \"\"\"Create visualizations for the dataset\"\"\"\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # 1. Class Distribution\n",
    "    plt.subplot(2, 2, 1)\n",
    "    sns.countplot(data=data, x='Class')\n",
    "    plt.title(f'Class Distribution in {set_name}')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # 2. Text Length Distribution by Class\n",
    "    plt.subplot(2, 2, 2)\n",
    "    sns.boxplot(data=data, x='Class', y='text_length')\n",
    "    plt.title('Text Length Distribution by Class')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # 3. Word Count Distribution by Class\n",
    "    plt.subplot(2, 2, 3)\n",
    "    sns.boxplot(data=data, x='Class', y='word_count')\n",
    "    plt.title('Word Count Distribution by Class')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # 4. Script Distribution\n",
    "    plt.subplot(2, 2, 4)\n",
    "    sns.countplot(data=data, x='script', hue='Class')\n",
    "    plt.title('Script Distribution by Class')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{set_name.lower()}_analysis.png')\n",
    "    plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Running the Analysis\n",
    "\n",
    "Now, we will run the analysis on a sample dataset to demonstrate the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_ma = pd.read_csv('../data/dev_ma.csv')\n",
    "dev_ta = pd.read_csv('../data/dev_ta.csv')\n",
    "train_ma = pd.read_csv('../data/train_ma.csv')\n",
    "train_ta = pd.read_csv('../data/train_ta.csv')\n",
    "\n",
    "for data, set_name in [(dev_ma, \"Dev Malayalam\"), (dev_ta, \"Dev Tamil\"), \n",
    "                       (train_ma, \"Train Malayalam\"), (train_ta, \"Train Tamil\")]:\n",
    "    \n",
    "    analyzed_data = analyze_dataset(data, set_name)\n",
    "\n",
    "    plot_distributions(analyzed_data, set_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eadb91ee0f3fef3c4d4762294d6d5438aa6e97dc12f16a4929ad9907f134b30d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
